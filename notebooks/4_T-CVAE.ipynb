{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [17:57:05] Enabling RDKit 2019.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from dgl import batch, unbatch\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit import RDLogger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os,sys,inspect\n",
    "sys.path.insert(0,'/home/icarus/app/src') \n",
    "\n",
    "from models.jtnn_vae import DGLJTNNVAE\n",
    "from models.modules import *\n",
    "\n",
    "#from .nnutils import cuda, move_dgl_to_cuda\n",
    "\n",
    "#from .jtnn_enc import DGLJTNNEncoder\n",
    "#from .jtnn_dec import DGLJTNNDecoder\n",
    "#from .mpn import DGLMPN\n",
    "#from .mpn import mol2dgl_single as mol2dgl_enc\n",
    "#from .jtmpn import DGLJTMPN\n",
    "#from .jtmpn import mol2dgl_single as mol2dgl_dec\n",
    "\n",
    "import os,sys,inspect\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0,'/home/icarus/T-CVAE-MolGen/src')\n",
    "\n",
    "from utils.chem import set_atommap, copy_edit_mol, enum_assemble_nx, \\\n",
    "                            attach_mols_nx, decode_stereo\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCVAE(nn.Module):\n",
    "    def __init__(self, vocab, hidden_size, latent_size, depth):\n",
    "        super(TCVAE, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latent_size = latent_size\n",
    "        self.depth = depth\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab.size(), hidden_size).cuda()\n",
    "        self.mpn = MPN(hidden_size, depth)\n",
    "        self.encoder = None  #\n",
    "        self.decoder = None  #\n",
    "        \n",
    "        self.T_mean, self.T_var = nn.Linear(hidden_size, latent_size // 2), \\\n",
    "                                  nn.Linear(hidden_size, latent_size // 2)\n",
    "        self.G_mean, self.G_var = nn.Linear(hidden_size, latent_size // 2), \\\n",
    "                                  nn.Linear(hidden_size, latent_size // 2)\n",
    "            \n",
    "        self.n_nodes_total = 0\n",
    "        self.n_edges_total = 0\n",
    "        self.n_passes = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior\n",
    "\n",
    "As in <cite data-cite=\"7333468/6Y976JUQ\"></cite>\n",
    "\n",
    "$q(z|x,y) \\sim N(\\mu,\\sigma^2I)$, where\n",
    "\n",
    "$\\quad\\quad h = \\text{MultiHead}(c,E_\\text{out}^L(x;y),E_\\text{out}^L(x;y))$\n",
    "\n",
    "$\\quad\\quad \\begin{bmatrix}\\mu\\\\\\log(\\sigma^2)\\end{bmatrix} = hW_q+b_q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def sample_posterior(self, prob_decode=False):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior\n",
    "\n",
    "As in <cite data-cite=\"7333468/6Y976JUQ\"></cite>\n",
    "\n",
    "$p_\\theta (z|x) \\sim N(\\mu', \\sigma'^2 I)$, where:\n",
    "\n",
    "$\\quad\\quad h' = \\text{MultiHead}(c, E_\\text{out}^L(x), E_\\text{out}^L(x))$\n",
    "\n",
    "$\\quad\\quad \\begin{bmatrix}\\mu'\\\\\\log(\\sigma'^2)\\end{bmatrix} = MLP_p(h')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def sample_prior(self, prob_decode=False):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Loading data...\n",
      "Loading finished.\n",
      "\tNum samples: 220011\n",
      "\tVocab file: /home/icarus/.dgl/jtnn/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "from utils.data import JTNNDataset, JTNNCollator\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "class ArgsTemp():\n",
    "    def __init__(self, hidden_size, depth, device):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = 300\n",
    "        self.latent_size = 56\n",
    "        self.depth = depth\n",
    "        self.device = device\n",
    "        self.lr = 1e-3\n",
    "        self.beta = 1.0\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        \n",
    "args = ArgsTemp(200,3, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(args.depth)\n",
    "\n",
    "dataset = JTNNDataset(data='train', vocab='vocab', training=True, intermediates=False)\n",
    "vocab = dataset.vocab\n",
    "\"\"\"\n",
    "dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        collate_fn=JTNNCollator(vocab, True, intermediates=False),\n",
    "        drop_last=True,\n",
    "        worker_init_fn=None)\n",
    "        \"\"\"\n",
    "\n",
    "model = DGLJTNNVAE(vocab, args.hidden_size, args.latent_size, args.depth, args).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCH = 100\n",
    "PRINT_ITER = 20\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os import access, R_OK\n",
    "from os.path import isdir\n",
    "\n",
    "save_path = '/home/icarus/app/data/05_model_output'\n",
    "assert isdir(save_path) and access(save_path, R_OK), \\\n",
    "       \"File {} doesn't exist or isn't readable\".format(save_path)\n",
    "\n",
    "def train():\n",
    "    dataset.training = True\n",
    "    dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            collate_fn=JTNNCollator(vocab, True),\n",
    "            drop_last=True,\n",
    "            worker_init_fn=None)\n",
    "\n",
    "    for epoch in range(MAX_EPOCH):\n",
    "        word_acc,topo_acc,assm_acc,steo_acc = 0,0,0,0\n",
    "        print(\"Epoch %d: \" % epoch)\n",
    "\n",
    "        for it, batch in tqdm(enumerate(dataloader),total=len(dataloader)):\n",
    "            model.zero_grad()\n",
    "            try:\n",
    "                loss, kl_div, wacc, tacc, sacc, dacc = model(batch, args.beta)\n",
    "            except:\n",
    "                print([t.smiles for t in batch['mol_trees']])\n",
    "                raise\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            word_acc += wacc\n",
    "            topo_acc += tacc\n",
    "            assm_acc += sacc\n",
    "            steo_acc += dacc\n",
    "\n",
    "            if (it + 1) % PRINT_ITER == 0:\n",
    "                word_acc = word_acc / PRINT_ITER * 100\n",
    "                topo_acc = topo_acc / PRINT_ITER * 100\n",
    "                assm_acc = assm_acc / PRINT_ITER * 100\n",
    "                steo_acc = steo_acc / PRINT_ITER * 100\n",
    "\n",
    "                print(\"KL: %.1f, Word: %.2f, Topo: %.2f, Assm: %.2f, Steo: %.2f, Loss: %.6f\" % (\n",
    "                    kl_div, word_acc, topo_acc, assm_acc, steo_acc, loss.item()))\n",
    "                word_acc,topo_acc,assm_acc,steo_acc = 0,0,0,0\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            if (it + 1) % 1500 == 0: #Fast annealing\n",
    "                scheduler.step()\n",
    "                print(\"learning rate: %.6f\" % scheduler.get_lr()[0])\n",
    "                \n",
    "            if (it + 1) % 100 == 0:\n",
    "                torch.save(model.state_dict(),\n",
    "                            save_path + \"/model.iter-%d-%d\" % (epoch, it + 1))\n",
    "\n",
    "        scheduler.step()\n",
    "        print(\"learning rate: %.6f\" % scheduler.get_lr()[0])\n",
    "        torch.save(model.state_dict(), save_path + \"/model.iter-\" + str(epoch))\n",
    "\n",
    "def test():\n",
    "    dataset.training = False\n",
    "    dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            collate_fn=JTNNCollator(vocab, False),\n",
    "            drop_last=True,\n",
    "            worker_init_fn=worker_init_fn)\n",
    "\n",
    "    # Just an example of molecule decoding; in reality you may want to sample\n",
    "    # tree and molecule vectors.\n",
    "    for it, batch in enumerate(dataloader):\n",
    "        gt_smiles = batch['mol_trees'][0].smiles\n",
    "        print(gt_smiles)\n",
    "        model.move_to_cuda(batch)\n",
    "        _, tree_vec, mol_vec = model.encode(batch)\n",
    "        tree_vec, mol_vec, _, _ = model.sample(tree_vec, mol_vec)\n",
    "        smiles = model.decode(tree_vec, mol_vec)\n",
    "        print(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 19/733 [12:56<9:00:05, 45.39s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL: 0.1, Word: 19.91, Topo: 74.10, Assm: 33.09, Steo: 21.26, Loss: 66.228661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 39/733 [25:47<8:27:41, 43.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL: 0.6, Word: 30.18, Topo: 85.35, Assm: 41.57, Steo: 26.16, Loss: 55.948597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 59/733 [38:19<8:34:30, 45.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL: 0.9, Word: 38.24, Topo: 88.75, Assm: 50.85, Steo: 23.22, Loss: 50.182426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 79/733 [51:33<7:58:11, 43.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL: 0.7, Word: 45.32, Topo: 90.50, Assm: 55.23, Steo: 28.24, Loss: 45.417885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 80/733 [51:35<5:39:59, 31.24s/it]"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "train() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<div class=\"cite2c-biblio\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "7333468/6Y976JUQ": {
     "DOI": "10.24963/ijcai.2019/727",
     "URL": "https://doi.org/10.24963/ijcai.2019/727",
     "author": [
      {
       "family": "Wang",
       "given": "Tianming"
      },
      {
       "family": "Wan",
       "given": "Xiaojun"
      }
     ],
     "container-title": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19",
     "id": "7333468/6Y976JUQ",
     "issued": {
      "year": 2019
     },
     "page": "5233–5239",
     "page-first": "5233",
     "publisher": "International Joint Conferences on Artificial Intelligence Organization",
     "title": "T-CVAE: Transformer-Based Conditioned Variational Autoencoder for Story Completion",
     "type": "paper-conference"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:env] *",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
